# PropMatch Backend

A robust property data scraping and management system for South African real estate, specifically focused on Cape Town properties from Property24.

## ğŸ“Š Project Overview

- **Total Properties Scraped**: 1,657 Cape Town properties
- **Success Rate**: 80.2%
- **Data Source**: Property24.com
- **Database**: Supabase PostgreSQL
- **Scraping Engine**: FireCrawl API with intelligent resume capabilities

## ğŸ—‚ï¸ Project Structure

```
Backend/
â”œâ”€â”€ scrapers/                    # Web scraping modules
â”‚   â”œâ”€â”€ smart_resume_scraper.py  # Intelligent auto-resume scraper
â”‚   â”œâ”€â”€ enhanced_property24_scraper.py  # Core Property24 scraping logic
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ database/                    # Database operations
â”‚   â”œâ”€â”€ database.py             # Supabase PostgreSQL integration
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ models/                      # Data models
â”‚   â”œâ”€â”€ models.py               # PropertyData and POI models
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ config/                      # Configuration files
â”‚   â”œâ”€â”€ .env                    # Environment variables (gitignored)
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ data/                        # Scraped data
â”‚   â””â”€â”€ property24_production_20250605_165810.json  # Main dataset (1,657 properties)
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                   # This file
```

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Environment Setup
Create `config/.env` file with your API keys:
```env
# FireCrawl API Keys (for scraping)
FIRECRAWL_API_KEY_1=fc-your-key-1
FIRECRAWL_API_KEY_2=fc-your-key-2
# ... up to 6 keys

# Supabase Configuration
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_DB_PASSWORD=your-database-password
SUPABASE_ANON_KEY=your-anon-key

# LangSmith Tracing (Optional - for AI observability)
LANGSMITH_API_KEY=your-langsmith-api-key
LANGSMITH_TRACING=true
LANGSMITH_PROJECT=PropMatch-Backend

# Scraping Configuration
MAX_CREDITS_PER_KEY=490
TOTAL_AVAILABLE_CREDITS=2940
MAX_SCRAPES_PER_MINUTE=10
```

## ğŸ” AI Observability

LangSmith integration provides complete visibility into AI operations:
- **Trace all AI calls** in real-time
- **Monitor token usage** and costs
- **Debug AI responses** and prompts
- **Track performance** metrics

See [LANGSMITH_SETUP.md](LANGSMITH_SETUP.md) for setup instructions.

### Database Features
- âœ… **PostgreSQL Integration**: Scalable relational database
- âœ… **JSON Field Support**: Complex data structures
- âœ… **Auto Migration**: JSON to database conversion
- âœ… **Data Validation**: Type checking and constraints
- âœ… **Performance Optimized**: Indexed searches

### AI Features
- âœ… **AI-Powered Search**: GPT-4o-mini for intelligent property ranking
- âœ… **Semantic Understanding**: Vector embeddings for property matching
- âœ… **Real-time Explanations**: AI-generated property match explanations
- âœ… **LangSmith Tracing**: Complete AI observability and debugging
- âœ… **Token Tracking**: Monitor AI usage and costs
- âœ… **Hybrid Search**: Vector + BM25 + AI scoring